{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022 Math80600A - Devoir 1 - PyTorch",
      "provenance": [],
      "collapsed_sections": [
        "uevQtU7NtZ_-",
        "5DeQOItkeQCx",
        "liuR-U0wea0n",
        "WGw4eEo-eeHm",
        "0rFL_Shoef3m",
        "O-bmI72yr7Gm",
        "I49qjiqHB9oa",
        "JwzKmdcuCv1D",
        "OZKyE2GUfL-Z",
        "E_YaASPpgRiL",
        "go55LVSJd-vG",
        "bMrKGlMQhCa0",
        "-A6AEOoigq68",
        "AWO5rjXuPIH5"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williamgrou/shopify_challenge/blob/main/2022_Math80600A_Devoir_1_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_LTBtfMBvW_"
      },
      "source": [
        "# Apprentissage automatique II: Apprentissage profond et ses applications\n",
        "# Devoir 1\n",
        "\n",
        "**Date de remise:  28 février**\n",
        "\n",
        "### Instructions\n",
        "- Faites une copie de ce bloc-notes sur votre propre Google Drive et répondez aux questions qui s'y trouvent.\n",
        "- Vous pouvez ajouter plus de cellules si nécessaire. Vous pouvez également ajouter des descriptions à votre code, bien que ce ne soit pas obligatoire.\n",
        "- Assurez-vous que le bloc-notes peut être exécuté par *Exécution -> Tout exécuter*. **Dérouler toutes les cellules** afin de faciliter l'évaluation.\n",
        "- Enregistrer le lien de votre bloc-notes [ici](https://forms.gle/cy7s6xan4Rvzy35D9). Veuillez **activer la modification ou les commentaires** afin que vous puissiez recevoir des commentaires des correcteur.trice.s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T33dD1e8tii2"
      },
      "source": [
        "Installation des bibliothèques Pytorch et Torchvision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJB3VQYDCUmh"
      },
      "source": [
        "!pip install -q torch torchvision torchtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l_Dl6qxCXmv"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uevQtU7NtZ_-"
      },
      "source": [
        "## 1) Opérations sur les tenseurs (30 points)\n",
        "\n",
        "Les opérations tensorielles sont importantes dans les modèles d'apprentissage profond. Dans cette partie, vous devrez implémenter certaines opérations tensorielles courantes en PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DeQOItkeQCx"
      },
      "source": [
        "### 1.1) Serrage (*squeezing*), desserrage (*unsqueezing*) et visualisage (*viewing*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAOmBE5ODwpP"
      },
      "source": [
        "Le serrage (squeezing), desserrage (unsqueezing) et visualisage (viewing) d'un tenseur sont des opérations importantes afin de changer les dimensions d'un tenseur. Comme nous l'avons vu dans le tutoriel, les fonctions de base sont [torch.squeeze](https://pytorch.org/docs/stable/torch.html#torch.squeeze), [torch.unsqueeze](https://pytorch.org/docs/stable/torch.html#torch.unsqueeze) et [torch.Tensor.view](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view). Veuillez lire la documentation associée et effectuez l'exercice suivante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVrM80YxFSjb"
      },
      "source": [
        "# x est un tenseur ayant pour dimension (3, 2)\n",
        "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "\n",
        "# Ajouter deux nouvelles dimensions à x en utilisant la fonction torch.unsqueeze, de façon telle à ce que les dimensions de x soient de (3,1,2,1.\n",
        "\n",
        "\n",
        "# Enlever les deux dimensions précédemment ajoutées en utilisant la fonction torch.squeeze de façon telle à retrouver les dimensions d'origine.\n",
        "\n",
        "\n",
        "# Utilisez la fonction torch.Tensor.view afin de transformer le tenseur en deux dimensions en un tenseur d'une unique dimension et de longeur 6.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liuR-U0wea0n"
      },
      "source": [
        "### 1.2) Concaténation et empilage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkbnt6v8Bo-j"
      },
      "source": [
        "La concaténation et l'empilage de tenseurs sont des opérations permettant de combiner de petits tenseurs en grands tenseurs.\n",
        "\n",
        "Les fonctions correspondantes sont [torch.cat](https://pytorch.org/docs/stable/torch.html#torch.cat) et [torch.stack](https://pytorch.org/docs/stable/torch.html#torch.stack). Veuillez lire la documentation associée et effectuez l'exercice suivante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9KqXu3Stfjh"
      },
      "source": [
        "# x est un tenseur ayant pour dimension (3, 2)\n",
        "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# y est un tenseur ayant pour dimension (3, 2)\n",
        "y = torch.Tensor([[-1, -2], [-3, -4], [-5, -6]])\n",
        "\n",
        "\n",
        "# Nous voulons créer un tenseur z de dimensions (2, 3, 2) tel que z[0,:,:] = x et z[1,:,:] = y.\n",
        "\n",
        "# Utilisez torch.stack pour créer pareil tenseur\n",
        "\n",
        "# Utilisez torch.cat et torch.unsqueeze pour créer pareil tenseur"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGw4eEo-eeHm"
      },
      "source": [
        "### 1.3) Expansion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAII9eJgJFK2"
      },
      "source": [
        "L'expansion d'un tenseur consiste à étendre un tenseur en un tenseur plus grand le long des dimensions du singleton. Les fonctions correspondantes sont [torch.Tensor.expand](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.expand) et [torch.Tensor.expand_as](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.expand_as). Veuillez lire la documentation associée et effectuez l'exercice suivante.\n",
        "\n",
        "\n",
        "Enfin, expliquez sous forme de commentaire en une ou deux phrases MAXIMUM quelles sont les différences entre les fonctions suivantes:\n",
        "\n",
        "```\n",
        "torch.Tensor.view()\n",
        "torch.Tensor.expand()\n",
        "torch.Tensor.reshape()\n",
        "torch.Tensor.repeat()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbFte-AJzVL"
      },
      "source": [
        "# x est un tenseur ayant pour dimension (3)\n",
        "x = torch.Tensor([1, 2, 3])\n",
        "\n",
        "# Nous voulons créer un tenseur z de dimensions (3, 2) tel que z[0,:] = x, z[1,:] = x.\n",
        "\n",
        "# Changez la dimension de x en un tenseur de dimension (1, 3) à l'aide de torch.unsqueeze\n",
        "\n",
        "# Déroulez ensuite le nouveau tenseur au tenseur cible en utilisant torch.Tensor.expand."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rFL_Shoef3m"
      },
      "source": [
        "### 1.4) Réduction pour une dimension choisie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmEoJVw0LL9H"
      },
      "source": [
        "En apprentissage profond, nous avons souvent besoin de calculer la valeur moyenne/somme/max/min dans une dimension donnée d'un tenseur. Veuillez vous référer [torch.mean](https://pytorch.org/docs/stable/torch.html#torch.mean), [torch.sum](https://pytorch.org/docs/stable/torch.html#torch.sum), [torch.max](https://pytorch.org/docs/stable/torch.html#torch.max), [torch.min](https://pytorch.org/docs/stable/torch.html#torch.min), [torch.topk](https://pytorch.org/docs/stable/torch.html#torch.topk) et complétez le code ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7dlZwe4MNxo"
      },
      "source": [
        "# x est un tenseur de dimension (10, 50)\n",
        "x = torch.randn(10, 50)\n",
        "\n",
        "# Calculez la valeur moyenne pour chaque ligne de x.\n",
        "# Vous devez générer un tenseur x_mean de taille (10), où x_mean[k] est la valeur moyenne de la k-ième ligne de x.\n",
        "\n",
        "# Calculer la valeur somme pour chaque ligne de x.\n",
        "# Vous devez générer un tenseur x_sum de taille (10).\n",
        "\n",
        "# Calculez la valeur maximale pour chaque ligne de x.\n",
        "# Vous devez générer un tenseur x_max de taille (10).\n",
        "\n",
        "# Calculez la valeur min pour chaque ligne de x.\n",
        "# Vous devez générer un tenseur x_min de taille (10).\n",
        "\n",
        "# Calculez les 5 plus grandes valeurs pour chaque ligne de x.\n",
        "# Vous devez générer un tenseur x_top de taille (10, 5), où x_top[k, :] est les 5 plus grandes valeurs de la k-ième ligne de x.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-bmI72yr7Gm"
      },
      "source": [
        "### 1.5) Opérations avancées\n",
        "\n",
        "En apprentissage profond, nous souhaitons souvent ne modifier qu'une partie d'un tenseur ou ne collecter que des valeurs à partir d'indices spécifiques. A ces fins, on utilise souvent ```torch.gather``` ou ```torch.scatter```, voir leur définition [ici](https://pytorch.org/docs/stable/tensors.html?highlight=scatter#torch.Tensor.scatter). \n",
        "\n",
        "Notez que vous **n'êtes pas obligé.e.s** d'utiliser ces fonctions et que certaines parties de la question peuvent ne pas en avoir besoin."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVUKcSlLtf-r"
      },
      "source": [
        "ind = torch.randint(50,(10,50))\n",
        "x = torch.randn(10,50,50)\n",
        "\n",
        "# Sélectionnez pour tout i,j les valeurs x[i,j,k] où ind[i,j] = k dans le tenseur\n",
        "# Le tenseur doit avoir la forme (10,50)\n",
        "\n",
        "# Doublez pour tout i,j les valeurs x[i,j,k] où ind[i,j] = k en laissant toutes les autres valeurs de x intactes\n",
        "# Le tenseur retourné doit avoir la forme (10,50,50)\n",
        "\n",
        "ind = ind[:, 0]\n",
        "# Sélectionnez les valeurs de x[i,l,j] où l = ind[k] pour tous les i,j,k\n",
        "# Le tenseur retourné doit avoir la forme (10,10,50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I49qjiqHB9oa"
      },
      "source": [
        "## 2) CNNs (40 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JePbG5pSt1xv"
      },
      "source": [
        "Implémentez un CNN pour la classification d'images sur l'ensemble de données CIFAR-10.\n",
        "\n",
        "CIFAR-10 est un jeu de données d'images de 10 catégories. Chaque image a une taille de 32x32 pixels. Le code suivant téléchargera l'ensemble de données et le divisera en *train* et *test*.\n",
        "\n",
        "Pour cette question, nous divisons les données d'entrainement (80 %) et de validation (20 %) pour la sélection des hyperparamètres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnPc57fIwQj0"
      },
      "source": [
        "t= torchvision.transforms.ToTensor()\n",
        "train_dataset = torchvision.datasets.CIFAR10(\"./data\", train=True, download=True, transform=t)\n",
        "test_dataset = torchvision.datasets.CIFAR10(\"./data\", train=False, download=True, transform=t)\n",
        "\n",
        "N = len(train_dataset)\n",
        "indices = np.arange(N)\n",
        "np.random.shuffle(indices)\n",
        "n = int(0.8 * N)\n",
        "print('{} for training,\\t{} for validation'.format(n, N-n))\n",
        "train_indices = indices[:n]\n",
        "valid_indices = indices[n:]\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "valid_sampler = torch.utils.data.SubsetRandomSampler(valid_indices)\n",
        "\n",
        "# Entrainement du modele\n",
        "# NE PAS MODIFIER\n",
        "def train(model, dataloader, optimizer, criterion):\n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.train()\n",
        "    for X, y in dataloader:\n",
        "        logits = model(X.cuda())\n",
        "        predictions = torch.max(logits, dim=-1)[1]\n",
        "        loss = criterion(logits, y.cuda())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        total_correct += torch.eq(predictions, y.cuda()).sum().item()\n",
        "        total_prediction += y.size(0)\n",
        "    return total_loss / len(dataloader), total_correct / total_prediction\n",
        "\n",
        "# Évalation du modele\n",
        "# NE PAS MODIFIER\n",
        "def evaluate(model, dataloader, criterion):  \n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            logits = model(X.cuda())\n",
        "            predictions = torch.max(logits, dim=-1)[1]\n",
        "            loss = criterion(logits, y.cuda())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += torch.eq(predictions, y.cuda()).sum().item()\n",
        "            total_prediction += y.size(0)\n",
        "    return total_loss / len(dataloader), total_correct / total_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieBpiwMwi6wD"
      },
      "source": [
        "Le code suivant permet de visualiser certains exemples dans l'ensemble de données. Vous pouvez l'utiliser pour déboguer votre modèle si nécessaire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzZ_UvgNwSYa"
      },
      "source": [
        "def plot(data, labels=None, num_sample=5):\n",
        "  n = min(len(data), num_sample)\n",
        "  for i in range(n):\n",
        "    plt.subplot(1, n, i+1)\n",
        "    plt.imshow(data[i], cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    if labels is not None:\n",
        "      plt.title(labels[i])\n",
        "\n",
        "train_dataset.labels = [train_dataset.classes[target] for target in train_dataset.targets]\n",
        "plot(train_dataset.data, train_dataset.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwzKmdcuCv1D"
      },
      "source": [
        "### 2.1) Rudiments pour l'implémentation d'un CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbEYo5WgjTtm"
      },
      "source": [
        "Soit un CNN vanille constitué de:\n",
        "\n",
        "- Trois couches de convolutions suivie d'une couche linéaire tel que vue lors de la troisième semaine.\n",
        "- Chaque couche de convolution est associée à un noyau de dimension 3, avec une marge de de zéros de dimension 1.\n",
        "- Une fonction d'activation ReLU après chaque couche cachée..\n",
        "\n",
        "Veuillez implémenter ce modèle dans la section suivante. Vous devrez ajuster les hyperparamètres et remplir les résultats dans le tableau."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZKyE2GUfL-Z"
      },
      "source": [
        "#### a) Implémentation des couches de convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P_aYytExtq9"
      },
      "source": [
        "\n",
        "Implémentez la fonction d'initialisation et la fonction de transfert du CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDmCKUD1LBFk"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    # initialisation des paramètres ici\n",
        "  \n",
        "  def forward(self, images):\n",
        "    # implémentation de la fonction forward ici\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_YaASPpgRiL"
      },
      "source": [
        "#### b) Sélection d'hyper paramètres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygMcDdpy6XWP"
      },
      "source": [
        "Entraînez le modèle CNN sur l'ensemble de données CIFAR-10. Sélectionnez le nombre de canaux (ou *feature maps*), l'optimiseur, le pas d'apprentissage et le nombre d'époques pour une meilleure précision de validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezqosnJbwUGC"
      },
      "source": [
        "# Sélectionnez le type d'optimiseur et les hyperparamètres avec le code suivant comme exemple\n",
        "batch_size = 128\n",
        "lr = 1e-4\n",
        "EPOCHS = 30\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "valid_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialisation du modèle\n",
        "model = CNN(...)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Apprentissage et phase de test\n",
        "# Vous pouvez réutiliser le bloc de codage suivant pour le réglage des hyperparamètres\n",
        "# N'hésitez pas à essayer des stratégies d'entraînement plus avancées\n",
        "best_valid_acc = 0.0\n",
        "best_state_dict = copy.deepcopy(model.state_dict())\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
        "\n",
        "    print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "    if valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc\n",
        "        best_state_dict = copy.deepcopy(model.state_dict())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-EHKzozkRbD"
      },
      "source": [
        "Notez les **performances de validation** de votre modèle sous différents paramètres d'hyperparamètres.\n",
        "\n",
        "**Indice:** Vous aurez peut-être besoin de plus d'époques pour SGD qu'Adam.\n",
        "\n",
        "| #Canaux pour chaque couche \\ optimiseur | SGD   | Adam  |\n",
        "|-------------------------------------|-------|-------|\n",
        "| (128, 128, 128)                     |       |       |\n",
        "| (256, 256, 256)                     |       |       |\n",
        "| (512, 512, 512)                     |       |       |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go55LVSJd-vG"
      },
      "source": [
        "### 2.2) Implémentation d'un RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G0eCj6OmOEE"
      },
      "source": [
        "Sur la base du CNN de la question précédente, implémentez un CNN complet avec une couche de *max pooling*.\n",
        "\n",
        "- Ajoutez une couche de *max pooling* après chaque couche de convolution.\n",
        "- Chaque couche de *max pooling* a une taille de noyau de 2 et une foulée (*stride*) de 2.\n",
        "\n",
        "Veuillez implémenter ce modèle dans la section suivante. Vous devrez ajuster les hyperparamètres et remplir les résultats dans le tableau. Vous devez également répondre aux questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMrKGlMQhCa0"
      },
      "source": [
        "#### a) CNN avec fonction de *max pooling*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2INt6P3Myd1"
      },
      "source": [
        "Copiez l'implémentation CNN dans la question précédente et initialisez les couches de *max pooling*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHu3Ic2dM1S9"
      },
      "source": [
        "class CNN_MaxPool(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_MaxPool, self).__init__()\n",
        "    # initialisation des paramètres ici\n",
        "  \n",
        "  def forward(self, images):\n",
        "    # implémentez la fonction forward ici\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A6AEOoigq68"
      },
      "source": [
        "#### b) Sélection d'hyper paramètres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drH4MHSVNqwz"
      },
      "source": [
        "Sur la base du meilleur optimiseur que vous avez trouvé dans le problème précédent, choisissez le nombre de canaux et le pas d'apprentissage pour une meilleure formance de validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgRRWGjnwWj-"
      },
      "source": [
        "# initialisation des hyper paramètres ici\n",
        "\n",
        "# entraînement du modèle là\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7Mu2ZZHoZU0"
      },
      "source": [
        "Notez la **précision de validation** de votre modèle sous différents paramètres et hyperparamètres.\n",
        "\n",
        "| #Canaux pour chaque couche | Performance de validation |\n",
        "|-------------------------|---------------------|\n",
        "| (128, 128, 128)         |                     |\n",
        "| (128, 256, 512)         |                     |\n",
        "| (256, 256, 256)         |                     |\n",
        "| (256, 512, 1024)        |                     |\n",
        "| (512, 512, 512)         |                     |\n",
        "| (512, 1024, 2048)       |                     |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UCaz8nWoWWS"
      },
      "source": [
        "Pour le meilleur modèle obtenue, testez-le sur l'ensemble de test.\n",
        "\n",
        "Aucun souci si vous avez trouvé une combinaison d'hyperparamètres meilleure que celles répertoriées dans les tableaux."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtidyfEvzEG1"
      },
      "source": [
        "# Évaluez le modèle ici\n",
        "# Entraînez le modèle sur l'ensemble d'entraînement\n",
        "# Trouvez le meilleur modèle/hyperparamètre avec l'ensemble de validation et appliquez ce meilleur modèle sur l'ensemble de test\n",
        "\n",
        "model.load_state_dict(best_state_dict)\n",
        "test_loss, test_acc = evaluate(model, test_dataloader, criterion)\n",
        "print('Test loss {:.3f} | Test acc {:.3f}'.format(test_loss, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSbhC8f1or6_"
      },
      "source": [
        "Quel est la **performance sur l'ensemble test** obtenue?\n",
        "\n",
        "**Votre réponse:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG3E9ZckomkX"
      },
      "source": [
        "Que pouvez-vous conclure pour la conception d'architectures d'un CNN ?\n",
        "\n",
        "**Votre réponse:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWO5rjXuPIH5"
      },
      "source": [
        "## 3) RNNs (40 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2AmIPwBJt9j"
      },
      "source": [
        "Utilisons PyTorch pour implémenter un RNN pour l'analyse des sentiments, c'est-à-dire classer les phrases sous l'une des trois catégories de sentiment, soit compris positifs, négatifs ou neutres.\n",
        "\n",
        "Nous utilisons un ensemble de données de référence (c'est-à-dire SST) pour cette tâche. Tout d'abord, téléchargeons l'ensemble de données SST et effectuons un prétraitement pour créer un vocabulaire et diviser l'ensemble de données en ensembles d'apprentissage/validation/test. Définissons également la fonction d'entraînement et d'évaluation. Veuillez ne pas modifier les fonctions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT8b2nr7Kq73"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "# telecharger les donnees et les diviser en sous ensembles\n",
        "train_data, val_data, test_data = datasets.SST.splits(TEXT, LABEL)\n",
        "\n",
        "# construction d'un dictionnaire\n",
        "TEXT.build_vocab(train_data)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "vocab_size = len(TEXT.vocab)\n",
        "label_size = len(LABEL.vocab)\n",
        "padding_idx = TEXT.vocab.stoi['<pad>']\n",
        "embedding_dim = 128\n",
        "hidden_dim = 128\n",
        "\n",
        "# construction des iterators\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size=32)\n",
        "\n",
        "# Apprentissage\n",
        "# NE PAS MODIFIER\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch.text.cuda())\n",
        "        predictions = torch.max(logits, dim=-1)[1]\n",
        "        loss = criterion(logits, batch.label.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        total_correct += torch.eq(predictions, batch.label.cuda()).sum().item()\n",
        "        total_prediction += batch.label.size(0)\n",
        "    return total_loss / len(iterator), total_correct / total_prediction\n",
        "\n",
        "# Evaluation\n",
        "# NE PAS MODIFIER\n",
        "def evaluate(model, iterator, criterion):  \n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            logits = model(batch.text.cuda())\n",
        "            predictions = torch.max(logits, dim=-1)[1]\n",
        "            loss = criterion(logits, batch.label.cuda())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += torch.eq(predictions, batch.label.cuda()).sum().item()\n",
        "            total_prediction += batch.label.size(0)\n",
        "    return total_loss / len(iterator), total_correct / total_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbWxFDZdK6rf"
      },
      "source": [
        "Ensuite, nous sommes prêts à construire notre RNN pour l'analyse des sentiments. Dans le code suivant, nous avons fourni plusieurs hyperparamètres dont nous avions besoin pour construire le modèle, y compris la taille du vocabulaire (vocab_size), la dimension d'intégration du mot (embedding_dim), la dimension de la couche cachée (hidden_dim), le nombre de couches (num_layers) et le nombre de catégories de phrases (label_size). Veuillez compléter le code  et implémenter un modèle RNN après avoir lu les instructions du dernier  [blocs](https://colab.research.google.com/drive/1D_ERWxDEFDKH92KjPVpL3dVObpiOIMqF#scrollTo=PbqSAz90zBYi)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWUKPgDGNQSr"
      },
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, label_size, padding_idx):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.label_size = label_size\n",
        "        self.num_layers = 1\n",
        "\n",
        "        # Ajoutez les couches requises pour l'analyse des sentiments.\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim, padding_idx=padding_idx)\n",
        "\n",
        "    def zero_state(self, batch_size): \n",
        "        # Implémente la fonction qui renvoie un état caché initial.\n",
        "        return None\n",
        "\n",
        "    def forward(self, text):\n",
        "        # Implémenter la fonction forward du modèle.\n",
        "        embedding = self.embedding(text)\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBX_xc9MN0gw"
      },
      "source": [
        "Enfin, nous sommes prêts à entraîner le modèle et à calculer ses performances.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQrU0wuUOIgb"
      },
      "source": [
        "# Sélectionnez le type d'optimiseur et les hyperparamètres avec le code suivant comme exemple\n",
        "batch_size = 128\n",
        "lr = 1e-4\n",
        "EPOCHS = 30\n",
        "\n",
        "# Initialisation du modèle\n",
        "model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.cuda()\n",
        "criterion.cuda()\n",
        "\n",
        "# Entraînement et test du modèle\n",
        "# Vous pouvez réutiliser le bloc de codage suivant pour la sélection des hyperparamètres\n",
        "# N'hésitez pas à essayer des stratégies d'entraînement plus avancées\n",
        "best_valid_acc = 0.0\n",
        "best_state_dict = copy.deepcopy(model.state_dict())\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "    if valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc\n",
        "        best_state_dict = copy.deepcopy(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EgT69I1reZ4"
      },
      "source": [
        "Une fois que nous avons trouvé les meilleurs hyperparamètres pour l'ensemble de validation, nous pouvons maintenant évaluer notre modèle sur l'ensemble de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPDvglccrdWt"
      },
      "source": [
        "# Évaluez le modèle ici\n",
        "# Entraînez le modèle sur l'ensemble d'apprentissage\n",
        "# Trouvez le meilleur modèle/hyperparamètre avec l'ensemble de validation et calculer ses performances sur l'ensemble de test\n",
        "\n",
        "model.load_state_dict(best_state_dict)\n",
        "test_loss, test_acc = evaluate(model, test_iter, criterion)\n",
        "print('Test loss {:.3f} | Test acc {:.3f}'.format(test_loss, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbqSAz90zBYi"
      },
      "source": [
        "### 3.1) Implémentation d'un RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_5KEDzgzVxT"
      },
      "source": [
        "Le code actuel du modèle RNN n'est pas complet, complétons donc d'abord le code pour implémenter un modèle RNN vanille en remplissant le [bloc](https://colab.research.google.com/drive/1D_ERWxDEFDKH92KjPVpL3dVObpiOIMqF#scrollTo=kWUKPgDGNQSr&line=3&uniqifier=1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiDCl9J0zIKO"
      },
      "source": [
        "- **Sous-tâche 1-1: Création de toutes les couches requises dans votre modèle**\n",
        "\n",
        "N'oubliez pas que lors de la construction d'un modèle d'apprentissage profond, nous devons d'abord compléter la fonction **init** en créant toutes les couches requises. Dans notre cas, puisque nous utilisons des RNNs pour la classification des phrases, nous avons besoin d'une couche d'intégration (*embedding*) pour transformer les mots en intégrations (*embedding*) de mots, d'une couche RNN pour transformer les intégrations (*embedding*) de mots en codages de phrases, d'une fonction d'activation et d'une couche linéaire ainsi que d'une fonction softmax pour le classement des phrases.\n",
        "\n",
        "Ceci étant, veuillez créer toutes les couches nécessaires de votre modèle RNN dans la fonction **init**. Notez que nous avons déjà ajouté la couche d'intégration de mots pour vous."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF_dE-TqzL0A"
      },
      "source": [
        "- **Sous-tâche 1-2: Implémentation de la fonction d'initialisation des états cachés**\n",
        "\n",
        "Rappelez-vous que lors de l'application d'une unité RNN pour transformer des intégrations (*embedding*) de mots en codages de phrases, l'unité RNN part d'un vecteur caché initial avec toutes les valeurs nulles et lit séquentiellement chaque mot pour mettre à jour le vecteur caché. Enfin, le vecteur caché obtenu après lecture du dernier mot est traité comme l'encodage de la phrase.\n",
        "\n",
        "Veuillez implémenter la fonction **zero_state**, qui renvoie un lot de vecteurs cachés initiaux en fonction d'une taille de lot (*batch*). Astuce : votre fonction doit renvoyer un tenseur avec toutes les valeurs nulles. Vous pouvez vous référer au [document officiel](https://pytorch.org/docs/stable/nn.html#rnn) pour définir les dimensions adéquates pour le tenseur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGiPTOnY28Iq"
      },
      "source": [
        "- **Sous-tâche 1-3: Implémentation de la fonction forward**\n",
        "\n",
        "Enfin, nous sommes prêts à construire la fonction *forward*, qui prend un lot de phrases en entrée et renvoie un lot de logits. Pour être plus précis, l'entrée est donnée par le tenseur appelé $\\text{text}$, et la taille du tenseur est $(B, L)$, $B$ étant la taille du lot, $L$ étant la longueur maximale des phrases dans ce lot et $\\text{text}[i, j]$ étant l'identifiant entier du $j$-ème mot dans la $i$-ème phrase. Étant donné le tenseur en entrée, votre fonction  doit renvoyer un tenseur logit de taille $(B, C)$, $B$ étant la taille du lot et $C$ étant le nombre de classes possibles.\n",
        "\n",
        "Veuillez implémenter la fonction de *forward* en fonction des instructions ci-dessus. Notez que nous avons déjà appliqué la couche d'intégration de mots à l'entrée de texte et obtenu un tenseur appelé $\\text{embedding}$, et la taille du tenseur est $(B, L, D)$, où $D$ est le mot dimension d'intégration. Vous pouvez directement opérer sur le tenseur $\\text{embedding}$ pour calculer les logits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUL9zYw4y_IZ"
      },
      "source": [
        "### 3.2) Étude des différents optimiseurs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeKKFSkzzUA_"
      },
      "source": [
        "Lors de la tâche précédente, nous avons implémenté un modèle RNN pour l'analyse des sentiments, ou plus généralement la classification des phrases.\n",
        "\n",
        "Pour mieux comprendre plusieurs concepts en apprentissage profond, faisons quelques études d'ablation en utilisant le modèle que nous venons d'implémenter.\n",
        "\n",
        "La première tâche consiste à essayer différents optimiseurs pour votre modèle, où pour chaque optimiseur, vous pouvez également essayer différentes valeurs de pas d'apprentissage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNlnDbZtqHgi"
      },
      "source": [
        "- **Sous-tâche 2-1: Remplir le tableau**\n",
        "\n",
        "Nous avons fourni le tableau suivant pour différentes combinaisons d'optimiseurs et de pas d'apprentissage. Veuillez noter la **performance de validation** de votre modèle avec différents optimiseurs et taux d'apprentissage.\n",
        "\n",
        "|         | 0.1  | 0.01 | 0.001|0.0001|\n",
        "|---------|------|------|------|------|\n",
        "| SGD     |      |      |      |      |\n",
        "| Adam    |      |      |      |      |\n",
        "| RMSprop |      |      |      |      |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVVd5b9rzSFA"
      },
      "source": [
        "- **Sous-tâche 2-2: Expliquez vos résultas**\n",
        "\n",
        "En fonction de vos résultats, expliquez BRIÈVEMENT vos observations, par exemple, quel optimiseur fonctionne le mieux, quel est le taux d'apprentissage optimal pour chaque optimiseur ?\n",
        "\n",
        "*Votre réponse:*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyy7qpHtzYJn"
      },
      "source": [
        "### 3.3) Comparez les résultats en fonction du nombre d'époques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhXQERRizZO6"
      },
      "source": [
        "Nous comparerons les résultats de notre modèle pour différents nombres d'époques d'entraînement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JBBjTGd1zis"
      },
      "source": [
        "- **Sous-tâche 3-1: Completez le talbeau**\n",
        "\n",
        "Veuillez présenter les **performances d'entraînement et de validation** de votre modèle avec différents nombres d'époques d'entraînement dans le tableau suivant.\n",
        "\n",
        "|                    |  10  |  20  |  30  |  40  |  50  |\n",
        "|--------------------|------|------|------|------|------|\n",
        "| Performance d'entraînement  |      |      |      |      |      |\n",
        "| Performance de validation|      |      |      |      |      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l82_FjXazdod"
      },
      "source": [
        "- **Subtask 3-2: Répondre à la question**\n",
        "\n",
        "Est-il toujours préférable d'entraîner un modèle sur plusieurs époques ? Comment pouvons-nous décider quand arrêter l'entraînement?\n",
        "\n",
        "*Votre réponse:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "066JcRvAze7f"
      },
      "source": [
        "### 3.4) Étude de la capacité des modèles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agxhZpHYzjIR"
      },
      "source": [
        "En pratique, nous pouvons également faire varier la capacité de notre modèle afin de trouver le modèle optimal. Veuillez tester différentes configurations de votre modèle, lesquelles ont des capacités différentes. Sur la base de vos observations, veuillez également répondre à la question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fp2QC2Pzkja"
      },
      "source": [
        "- **Sous-tâche 4-1: Complétez le tableau**\n",
        "\n",
        "Veuillez noter la **performance de validation** de votre modèle pour différentes capacités de modèle (c'est-à-dire, spécifiée par les termes  *embedding dim* et *couche cachée dim*).\n",
        "\n",
        "|Embedding dim / Couche cachée dim |  64  |  128  |  256 |\n",
        "|---------------------------|------|-------|------|\n",
        "| 64                        |      |       |      |\n",
        "| 128                       |      |       |      |\n",
        "| 256                       |      |       |      |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY-OzP6E4JWU"
      },
      "source": [
        "- **Sous-tâche 4-2: Répondre à la question**\n",
        "\n",
        "Est-il toujours préférable d'augmenter la capacité du modèle dans ce cas? Est-il toujours préférable d'augmenter la capacité du modèle en général? Comment décider de la bonne capacité du modèle en pratique ?\n",
        "\n",
        "*Votre réponse:*\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XbnXoMQARgi6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}